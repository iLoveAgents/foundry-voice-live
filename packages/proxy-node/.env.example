# Foundry Voice Live Proxy - Configuration

# ============================================================================
# Server Configuration
# ============================================================================
PORT=8080
API_VERSION=2025-10-01

# ============================================================================
# Security Configuration
# ============================================================================
# Comma-separated list of allowed origins (CORS)
# Use * for development only (not recommended for production)
ALLOWED_ORIGINS=http://localhost:3000,https://myapp.com

# Rate limiting (per IP address)
RATE_LIMIT_WINDOW_MS=60000
RATE_LIMIT_MAX_REQUESTS=100

# Maximum concurrent WebSocket connections
MAX_CONNECTIONS=1000

# ============================================================================
# Telemetry Configuration (Optional)
# ============================================================================
# Application Insights connection string
# If not provided, logging will be console-only
# APPLICATIONINSIGHTS_CONNECTION_STRING=InstrumentationKey=00000000-0000-0000-0000-000000000000;IngestionEndpoint=https://...

# ============================================================================
# Azure AI Foundry Resource (Required)
# ============================================================================
AZURE_AI_FOUNDRY_RESOURCE=your-resource-name

# ============================================================================
# Authentication: API Key (Optional)
# ============================================================================
# For Standard Mode anonymous auth - API key is secured in backend
# If not provided, client must send MSAL token in URL (converted to header by proxy)
AZURE_SPEECH_KEY=your-api-key-here

# ============================================================================
# Proxy Responsibilities
# ============================================================================
# 1. Move MSAL token from URL to Authorization header (browser WebSocket limitation)
# 2. Hide API key on server (not exposed to browser)
# 3. Transparent pass-through of all other parameters to Azure API
#
# The proxy is transparent - client uses same parameters as Azure API:
# https://learn.microsoft.com/azure/ai-services/openai/realtime-audio-reference
#
# ============================================================================
# Usage Examples
# ============================================================================
# Mode is automatically detected from URL parameters:
# - Agent mode: When agentId AND projectName are present in URL
# - Standard mode: Otherwise (Voice/Avatar)
#
# Standard Mode - Voice/Avatar with API key (anonymous):
#   ws://localhost:8080/ws?model=gpt-realtime
#
# Standard Mode - Voice/Avatar with MSAL token (user-level):
#   ws://localhost:8080/ws?model=gpt-realtime&token=MSAL_TOKEN
#
# Agent Mode - Agent Service with MSAL token:
#   ws://localhost:8080/ws?agentId=YOUR_AGENT_ID&projectName=YOUR_PROJECT&token=MSAL_TOKEN
#
# Note: Client must provide agentId and projectName in URL for Agent mode
#       (no .env fallback - proxy is transparent)
